{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the Code\n",
    "This code has been performed on eeg data collected from [NeuroSky headset](https://store.neurosky.com/pages/mindwave).\n",
    "\n",
    "This is not the exact code that was used to perform the experimentation, but rather a guideline on our implementation for Image Recall test performed by a set of users on a series of images of flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### user-folder-name refers to a folder inside the data folder for any particular user\n",
    "path ='data/user-folder-name/' # use your path\n",
    "allFiles = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "\n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    '''\n",
    "    alist.sort(key=natural_keys) sorts in human order\n",
    "    http://nedbatchelder.com/blog/200712/human_sorting.html\n",
    "    (See Toothy's implementation in the comments)\n",
    "    '''\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]\n",
    "\n",
    "\n",
    "allFiles.sort(key=natural_keys)\n",
    "print(allFiles)\n",
    "    \n",
    "\n",
    "eeg = pd.DataFrame()\n",
    "list_=[]\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    list_.append(df)\n",
    "    \n",
    "### concat all the data for all the tests in a single pandas dataframe\n",
    "eeg = pd.concat(list_)\n",
    "### user-file-name is a file name containing results for each user.\n",
    "event = pd.read_csv('result/user-file-name.csv', sep=',', low_memory=False)\n",
    "\n",
    "# CLEAN THE DATA\n",
    "\n",
    "### remove all the rows where the result is -1 which means the user could not submit an answer for that question\n",
    "event = event.loc[event['result'] != -1]\n",
    "### remove unnecessary columns from data  \n",
    "eeg = eeg.drop(eeg.columns[[1, 4, 5 , 6, 9, 10 , 11, 12, 13, 14, 15, 16]], axis=1)\n",
    "\n",
    "### remove duplicates based on timestamp\n",
    "eeg = eeg.dropna()\n",
    "event = event.dropna()\n",
    "eeg = eeg.drop_duplicates(['timestampMs'], keep='last')\n",
    "    \n",
    "### pad values to list              REMOVE PADDING IF ERRORS.\n",
    "#res['res']=res['res'][:eeg['timestampMs'].count()] + [0]*(eeg['timestampMs'].count()-len(res['res']))\n",
    "\n",
    "### remove the timestamps from training data \n",
    "eeg=eeg.drop(eeg.columns[[0]], axis=1)\n",
    "\n",
    "### reset the indices\n",
    "eeg = eeg.reset_index(drop=True)\n",
    "\n",
    "### convert to np array\n",
    "eeg=eeg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "samples = []\n",
    "### length is the average length of a question answering event.\n",
    "length = math.ceil(len(eeg)/len(event))\n",
    "\n",
    "eeg = np.pad(eeg, ((0, len(event)*length - len(eeg)),(0,0)), 'constant')\n",
    "\n",
    "eeg = np.reshape(eeg, (len(event), length, 4))\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=seed)\n",
    "\n",
    "result = np.array(event['result'])\n",
    "\n",
    "sss.get_n_splits(eeg, result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for train_index, test_index in sss.split(eeg, result):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = eeg[train_index], eeg[test_index]\n",
    "    y_train, y_test = result[train_index], result[test_index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "\n",
    "# code for building an LSTM with 100 neurons and dropout. Runs for 50 epochs\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, return_sequences=False, input_shape=(length, 4)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "his=[]\n",
    "\n",
    "for train_index, test_index in sss.split(eeg, result):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = eeg[train_index], eeg[test_index]\n",
    "    y_train, y_test = result[train_index], result[test_index]\n",
    "    history = model.fit(X_train, y_train, batch_size=length, epochs=100)\n",
    "    score = model.evaluate(X_test, y_test, batch_size=length)\n",
    "    his.append(history)\n",
    "    print(np.mean(history.history['acc']))\n",
    "    print(score)\n",
    "\n",
    "\n",
    "### save the model\n",
    "model.save('your_model_name.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(history.history['acc']) # numpy assumed imported as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum=0\n",
    "for h in his:\n",
    "    sum=sum+np.mean(h.history['acc'])\n",
    "print(sum/len(his))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
